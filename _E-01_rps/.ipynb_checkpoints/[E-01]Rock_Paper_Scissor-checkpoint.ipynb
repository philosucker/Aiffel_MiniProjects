{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/mini_projects/rps/train/scissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/mini_projects/rps/train/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/mini_projects/rps/train/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/mini_projects/rps/train/scissor\"\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "target_size=(28,28) \n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/mini_projects/rps/train/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/mini_projects/rps/train/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련 데이터 적재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 루브릭 평가문항 2. 오버피팅을 극복하기 위한 적절한 시도가 있었는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. 훈련 데이터셋에 소요된 총 이미지 개수 5702 장  / 테스트 데이터 셋에 소요된 총 이미지 개수 643장\n",
    "1. 훈련 데이터셋과 테스트 데이터셋의 구분\n",
    "2. 테스트 데이터셋의 이미지들은 훈련 데이터셋 있는 이미지들과 최대한 다른 이미지들로 선별하여 분류\n",
    "3. 데이터 normalization 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 5698 입니다.\n",
      "x_train shape: (5702, 28, 28, 3)\n",
      "y_train shape: (5702,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data= 5702  \n",
    "    img_size=28\n",
    "    color=3 \n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/mini_projects/rps/train/\"   \n",
    "\n",
    "(x_train, y_train)=load_data(image_dir_path)    # 핵심 함수 : 훈련데이터의 입력과 레이블 생성하는 함수!!\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 데이터 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0  최대값: 255\n"
     ]
    }
   ],
   "source": [
    "print('최소값:',np.min(x_train), ' 최대값:',np.max(x_train))\n",
    "\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "# Conv2D(16) 얼마나 다양한 이미지의 특징을 살펴볼 것인가? (입력 이미지가 다양할 수록 더 많은 특징 고려 필요)\n",
    "# input_shape=(28,28,3) >> 입력 이미지의 형태 3 : 채널 정보 컬러사진 RGB니까 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "# Conv2D(32) 얼마나 다양한 이미지의 특징을 살펴볼 것인가? (입력 이미지가 다양할 수록 더 많은 특징 고려 필요)\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "# Dense(32) : 분류기 알고리즘을 얼마나 복잡하게 할 것인가? (복잡한 문제일 수록 이 숫자를 늘린다) \n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "# 최종 분류기의 클래스 숫자 3 : 가위, 바위, 보\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 훈련 (훈련 데이터 셋 학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "179/179 [==============================] - 4s 20ms/step - loss: 0.9591 - accuracy: 0.5284\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.7524\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8430\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8923\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9225\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9476\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9593\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9730\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9819\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f63e8582250>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 루브릭 평가문항 1. 이미지 분류기 모델이 성공적으로 만들어졌는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >훈련결과 : 정확도 98%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 데이터 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 642 입니다.\n",
      "x_test shape: (643, 28, 28, 3)\n",
      "y_test shape: (643,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=643   \n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/mini_projects/rps/test/\"\n",
    "\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0  최대값: 255\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('최소값:',np.min(x_test), ' 최대값:',np.max(x_test))\n",
    "\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터로 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 2s - loss: 0.1270 - accuracy: 0.9533\n",
      "test_loss: 0.1270076036453247 \n",
      "test_accuracy: 0.9533436894416809\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >테스트 정확도: 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 11, 11, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 448,003\n",
      "Trainable params: 448,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "179/179 [==============================] - 4s 23ms/step - loss: 0.9338 - accuracy: 0.5335\n",
      "Epoch 2/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7832\n",
      "Epoch 3/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8881\n",
      "Epoch 4/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9321\n",
      "Epoch 5/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9639\n",
      "Epoch 6/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9747\n",
      "Epoch 7/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9828\n",
      "Epoch 8/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9893\n",
      "Epoch 9/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9960\n",
      "Epoch 10/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9979\n",
      "Epoch 11/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9996\n",
      "Epoch 12/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9998\n",
      "Epoch 13/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.9998\n",
      "Epoch 14/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.9998\n",
      "Epoch 15/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f63e83c6c50>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=128\n",
    "n_dense=128\n",
    "n_train_epoch=15\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 모델 재훈련\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 루브릭 평가문항 3. 분류모델의 test accuracy가 기준 (60%) 이상 높게 나왔는가? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >>최종결과 : 정확도 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 2s - loss: 0.0408 - accuracy: 0.9907\n",
      "test_loss: 0.04082171246409416 \n",
      "test_accuracy: 0.9906687140464783\n"
     ]
    }
   ],
   "source": [
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트 일지\n",
    "2020년 1월 5일과 6일 이틀에 걸쳐 작업을 했다.   \n",
    "   \n",
    "   \n",
    "__1. 1차 시기__   \n",
    "   \n",
    "훈련 데이터셋 3000장, 테스트 데이터셋 300장 으로 모델을 평가했다.   \n",
    "학습시 정확도는 90%가 넘었지만 테스트 정확도는 40%대에 머물렀다.   \n",
    "Conv2D 인자와 Dense 인자, 총 3개의 하이퍼 파라미터를   \n",
    "두자리 수부터 네자리 수까지 가능한 모든 조합으로 섞어   \n",
    "200여회 남짓 모델을 돌려보았지만   \n",
    "테스트 정확도가 60%를 넘지 못했다.   \n",
    "   \n",
    "__2. 1차 시기의 실패__   \n",
    "   \n",
    "데이터의 질을 고려해 보면, 하이퍼 파라미터의 조정은 그렇게 큰 영향을 끼치지 않는 것 같다는 생각이 든다.   \n",
    "같은 팀원 중 한분이 훈련 데이터셋과 테스트 데이터셋에 쓴 이미지들을 선별했을 때 좋은 결과가 나왔다는 조언을 해주셨다.   \n",
    "(육안으로 가위,바위,보가 분명히 식별가능하고 이미지의 크기가 고르게)   \n",
    "   \n",
    "그런데 그렇게 하면 테스트 셋이 오염된다.   \n",
    "하지만 처음엔 나쁘기만 한 생각은 아니라고 생각했다.   \n",
    "데이터가 해석될 수 있는 경우의 수가 육안으로 보았을 때도 분명히 나누어 지지 않을 때    \n",
    "모델을 더 일반화시키는 데 한계가 있다면   \n",
    "데이터의 크기로 문제를 압도하는 게 의미가 있을까?   \n",
    "\n",
    "그래서 전체 데이터를 대상으로 이미지를 선별한 뒤   \n",
    "각각 훈련 데이터셋과, 테스트데이터셋에 나누어 분류하니   \n",
    "테스트 이미지는 218장, 훈련 이미지는 2301장만 남아   \n",
    "약 30%의 데이터 손실이 일어났다.   \n",
    "하지만 이렇게 했을 때도 최종 테스트 정확도가 50%를 넘지 못했다.   \n",
    "데이터 크기 자체가 너무 작기 때문이라고 생각된다.   \n",
    "이미지의 질을 높이지 않고 훈련/테스트셋의 크기가 각각 3000/300장 미만인 경우에 테스트 정확도가 높게 나올 수 있게 하는 방법이 있을까?\n",
    "   \n",
    "__3. 2차 시기__   \n",
    "   \n",
    "데이터의 크기를 조정해보았다.\n",
    "훈련 데이터 셋의 크기는 그대로 두고   \n",
    "테스트 데이터 셋의 크기를 2배 늘려 425장을 사용했다.   \n",
    "그 결과 테스트 정확도가 70%까지 나왔다.  \n",
    "   \n",
    "__4. 3차 시기__   \n",
    "   \n",
    "훈련 데이터셋의 크기도 2배로 늘려 4050장을 사용하고   \n",
    "테스트 데이터셋은 원래대로 218장을 사용했더니   \n",
    "최종 테스트 정확도가 100%까지 나왔다.   \n",
    "하지만 3차 시기의 경우 학습시 정확도가 97%였던 것에 비해   \n",
    "최초 테스트에서 99%가 나와   \n",
    "오버 피팅이 의심되었다. 추측컨대 늘어난 훈련데이터 셋에 테스트 데이터 셋이 섞여 들어갔을 가능성이 크다.   \n",
    "   \n",
    "__5. 4차 시기__   \n",
    "   \n",
    "훈련 데이터셋을 5702장, 테스트 데이터셋을 643장 사용하여 돌려본 결과  \n",
    "학습시 정확도는 98%   \n",
    "최초 테스트 정확도는 96%   \n",
    "하이퍼 파라미터 조정결과 99%가 나왔다.   \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고   \n",
    "   \n",
    "\n",
    "__이 프로젝트에서 데이터의 질이 중요한 문제였을까?__   \n",
    "   \n",
    "   처음에는\n",
    "1. 이미지의 퀄리티가 너무 낮기 때문에\n",
    "2. 다양한 각도에서 촬영한 가위, 바위, 보 이미지 대신 2차원 상에서 분명히 구분가능한 이미지 들로만 데이터를 정리한 뒤   \n",
    "3. 훈련데이터와 테스트데이터를 비슷한 수준의 이미지로 분류하여 모델을 돌림으로써   \n",
    "4. 이 프로젝트에서 기대할 수 있는 것은 문자 그대로 명백한 가위, 바위, 보 이미지를 분류해내는 것이 최선이다. 라고 생각했다.   \n",
    "5. 데이터의 크기를 충분히 키워서 완전히 랜덤하게 훈련셋과 테스트셋을 나눈 뒤   \n",
    "6. 데이터의 크기가 증가함에 따라 정확도가 올라가는 비례관계가 발견되긴 했지만, 그게 딱히 신뢰있게 다가오지 않았다.   \n",
    "7. 레이블은 주먹이라고 돼 있고 해당 폴더에 들어 있는 사진이니, 데이터 제공자가 실수하거나 날 속인 게 아니라면, 주먹이라고 생각해야 하지만   \n",
    "8. 도저히 주먹이라고 말하기 어려운 이미지와 같은 사례들이 분명히 있었기 때문이다.\n",
    "\n",
    "9. 그런데 내 생각이 중요할까?   \n",
    "10. 테스트셋이 그런 거면 그런 것이다. real world의 데이터란 그런 거니까.   \n",
    "11. 따라서 데이터의 질이 문제라면, 훈련셋에서 최대한 많은 데이터를 확보하면 되는 문제인 것이다.   \n",
    "\n",
    "__나아가 이 프로젝트에서 내가 무엇을 배웠는지를 더 생각해보았다.__   \n",
    "1. 그럼에도 불구하고 만약 이미지의 화질이 매우 높아 천태만상으로 찍힌 모든 사진들이 육안으로도 무엇인지 식별 가능한 수준이었다면   \n",
    "2. 그 때 중요한 건 데이터의 양 뿐만 아니라 보다 정교한 모델이 필요할 것이다.   \n",
    "3. 따라서 그런 경우에는 내가 다루고자 하는 또는 만들고자 하는 모델이 어느 정도 수준의 결과를 낼 수 있는 모델인지를 분명히 파악하고 있어야 한다. \n",
    "3. 또한 모델의 성능을 개선시키는 방법을 알지 못하면 1회용 모델을 만들게 될 뿐일 것이다.      \n",
    "4. 나의 지식 수준이 한참 낮아 원리를 모르는 상태에서 품는 의심들은 천개 중 하나가 쓸모 있으면 다행이다. 의심하기 전에 이해부터 시도하자.   \n",
    "\n",
    "   \n",
    "__더 공부해야할 부분__   \n",
    "함수가 길어지면 변수가 인자가 되고, 그 변수가 다시 다른 함수의 인자가 되고, 꼬리에 꼬리를 물면서 전체 그림을 놓친다.   \n",
    "기본적인 문자열 함수들에 대한 이해가 부족하다. 슬라이싱, 인덱싱 기법들...   \n",
    "넘파이 배열에 너무 약하다.   \n",
    "딥러닝 용어를 더 공부해야겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
