{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target_names : ['class_0' 'class_1' 'class_2'] \n",
      "\n",
      "wines 데이터의 자료형 : <class 'list'> \n",
      "\n",
      "wines 데이터에 담긴 정보들 : dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names']) \n",
      "\n",
      "wines 데이터의 feature의 shape(총 데이터수, 각 데이터가 갖고 있는 정보의 수) : (178, 13) \n",
      "\n",
      "wines 데이터의 총 label 개수 : (178,) \n",
      "\n",
      "wines 데이터의 각 feature와 target의 값 :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  label  \n",
       "0                            3.92   1065.0      0  \n",
       "1                            3.40   1050.0      0  \n",
       "2                            3.17   1185.0      0  \n",
       "3                            3.45   1480.0      0  \n",
       "4                            2.93    735.0      0  \n",
       "..                            ...      ...    ...  \n",
       "173                          1.74    740.0      2  \n",
       "174                          1.56    750.0      2  \n",
       "175                          1.56    835.0      2  \n",
       "176                          1.62    840.0      2  \n",
       "177                          1.60    560.0      2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import \n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# (2) 데이터 준비\n",
    "wines = load_wine()\n",
    "\n",
    "# (3) 데이터 이해하기\n",
    "\n",
    "# Feature Data 지정하기  (머신러닝 모델에게 입력되는 데이터를 feature 라고 부르기도 한다.)\n",
    "wines_data = wines.data\n",
    "\n",
    "# Label Data 지정하기\n",
    "wines_label = wines.target\n",
    "\n",
    "# Target Names 출력해 보기\n",
    "print(\"Target_names :\", wines.target_names, \"\\n\")\n",
    "\n",
    "# 데이터 Describe 해 보기\n",
    "print(\"wines 데이터의 자료형 :\", type(dir(wines)),\"\\n\")\n",
    "print(\"wines 데이터에 담긴 정보들 :\", wines.keys(),\"\\n\")\n",
    "print(\"wines 데이터의 feature의 shape(총 데이터수, 각 데이터가 갖고 있는 정보의 수) :\", wines_data.shape,\"\\n\")\n",
    "# print(\"wines 데이터의 feature의 맨 첫번째 데이터에 입력된 정보 :\", wines_data[0])\n",
    "print(\"wines 데이터의 총 label 개수 :\", wines_label.shape,\"\\n\")\n",
    "\n",
    "# print(digits.DESCR)\n",
    "\n",
    "wines_df = pd.DataFrame(data=wines_data, columns=wines.feature_names) \n",
    "wines_df[\"label\"] = wines.target\n",
    "print(\"wines 데이터의 각 feature와 target의 값 :\")\n",
    "wines_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines_data, \n",
    "                                                    wines_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state= 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix :  \n",
      " [[10  1  0]\n",
      " [ 1 16  1]\n",
      " [ 0  0  7]] \n",
      "\n",
      "classification_report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.94      0.89      0.91        18\n",
      "           2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.93      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (4) 모델 학습 및 예측, \n",
    "\n",
    "# 첫번째 알고리즘 : Decision Tree 92%\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(\"confusion_matrix : \",\"\\n\", confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "print(\"classification_report : \",\"\\n\", classification_report(y_test, y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix :  \n",
      " [[11  0  0]\n",
      " [ 0 18  0]\n",
      " [ 0  0  7]] \n",
      "\n",
      "classification_report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        18\n",
      "           2       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 두번째 알고리즘 : Random Forest 100%\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(\"confusion_matrix : \",\"\\n\", confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "print(\"classification_report : \",\"\\n\", classification_report(y_test, y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix :  \n",
      " [[ 8  0  3]\n",
      " [ 1 14  3]\n",
      " [ 0  3  4]] \n",
      "\n",
      "classification_report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80        11\n",
      "           1       0.82      0.78      0.80        18\n",
      "           2       0.40      0.57      0.47         7\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.70      0.69      0.69        36\n",
      "weighted avg       0.76      0.72      0.74        36\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 세번째 알고리즘 : Support Vector Machine 72%\n",
    "from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"confusion_matrix : \",\"\\n\", confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "print(\"classification_report : \",\"\\n\", classification_report(y_test, y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix :  \n",
      " [[ 8  0  3]\n",
      " [ 1 11  6]\n",
      " [ 2  0  5]] \n",
      "\n",
      "classification_report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        11\n",
      "           1       1.00      0.61      0.76        18\n",
      "           2       0.36      0.71      0.48         7\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.69      0.68      0.65        36\n",
      "weighted avg       0.79      0.67      0.69        36\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 네번째 알고리즘 : Stochastic Gradient Descent Classifier (SGDClassifier)  67%  \n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(\"confusion_matrix : \",\"\\n\", confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "print(\"classification_report : \",\"\\n\", classification_report(y_test, y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0.13  최대값: 1680.0\n",
      "최소값: 0.14  최대값: 1515.0\n"
     ]
    }
   ],
   "source": [
    "# 다섯번째 알고리즘 : Logistic Regression  69%\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print('최소값:',np.min(X_train), ' 최대값:',np.max(X_train))\n",
    "print('최소값:',np.min(X_test), ' 최대값:',np.max(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0.0005098039215686275  최대값: 6.588235294117647\n",
      "최소값: 0.0005490196078431374  최대값: 5.9411764705882355\n",
      "confusion_matrix :  \n",
      " [[ 8  0  3]\n",
      " [ 1 14  3]\n",
      " [ 1  3  3]] \n",
      "\n",
      "classification_report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76        11\n",
      "           1       0.82      0.78      0.80        18\n",
      "           2       0.33      0.43      0.38         7\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.65      0.64      0.65        36\n",
      "weighted avg       0.72      0.69      0.71        36\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# X_train 과 X_test Normalization\n",
    "X_train_norm = X_train/255.0 \n",
    "X_test_norm = X_test/255.0 \n",
    "\n",
    "print('최소값:',np.min(X_train_norm), ' 최대값:',np.max(X_train_norm))\n",
    "print('최소값:',np.min(X_test_norm), ' 최대값:',np.max(X_test_norm))\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "logistic_model.fit(X_train_norm, y_train)\n",
    "y_pred = logistic_model.predict(X_test_norm)\n",
    "\n",
    "print(\"confusion_matrix : \",\"\\n\", confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "print(\"classification_report : \",\"\\n\", classification_report(y_test, y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "와인 분류 문제에서 가장 좋은 성능을 낸 모델 : Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-5366686037eb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-5366686037eb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    이 문제는 총 178개의 와인을 3개의 카테고리로 분류하는 최고의 알고리즘을 찾는 문제다.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "이 문제는 총 178개의 와인을 3개의 카테고리로 분류하는 최고의 알고리즘을 찾는 문제다.\n",
    "이를 위해 각 와인 당 13개의 feature가 입력돼있다.\n",
    "랜덤 포레스트는 모든 지표에서 100%의 성적을 냈다.\n",
    "(3개의 와인 카테고리에서 각각 precision, recall, f1-score가 모두 100%)\n",
    "따라서 이 문제에 있어서는 랜덤 포레스트가 최선의 모델이라고 할 수 있다\n",
    "\n",
    "그렇다면 왜 랜덤 포레스트가 최고의 결과를 낼 수 있었던 걸까?\n",
    "타겟의 종류가 적고, 그에 비해 상대적으로 feature가 많은 문제에선 랜덤 포레스트가 좋은 성능을 낸다고 추론해볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winedml SVM 과 SGDClassifier 모델의 성적이 digits와 breast_cancer보다 유난히 떨어진다. 왜?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
