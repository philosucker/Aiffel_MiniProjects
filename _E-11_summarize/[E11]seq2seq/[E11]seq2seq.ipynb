{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/mini_projects/_E-11_summarize/data/news_summary_more.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98401\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    98280\n",
       "text         98360\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98379"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    98280\n",
       "text         98360\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Fearless Girl' statue to face New York Stock Exchange\""
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[34652,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The 'Fearless Girl' statue in New York will be relocated to a spot in front of the New York Stock Exchange, officials said. The bronze statue is currently placed near Wall Street. It was installed there last year to commemorate the International Women's Day and aims to highlight the message of a bigger role for women in the corporate sphere.\""
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[34652,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization  텍스트 정규화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #데이터 전처리 함수\n",
    "# def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "#     sentence = sentence.lower()\n",
    "#     sentence = BeautifulSoup(sentence, \"lxml\").text\n",
    "#     sentence = re.sub(r'\\([^)]*\\)', '', sentence)\n",
    "#     sentence = re.sub('\"','', sentence)\n",
    "#     sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")])\n",
    "#     sentence = re.sub(r\"'s\\b\",\"\", sentence)\n",
    "#     sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "#     sentence = re.sub('[m]{2,}', 'mm', sentence)\n",
    "    \n",
    "#     if remove_stopwords:\n",
    "#         tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "#     else:\n",
    "#         tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "#     return tokens\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence)\n",
    "    sentence = re.sub('\"','', sentence)\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")])\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence)\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence)\n",
    "    \n",
    "    tokens = ' '.join(word for word in sentence.split())\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = []\n",
    "\n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_headlines = []\n",
    "\n",
    "for s in data['headlines']:\n",
    "    clean_headlines.append(preprocess_sentence(s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98379"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련데이터 / 테스트데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 71\n",
      "텍스트의 평균 길이 : 57.927260899175636\n",
      "헤드라인의 최소 길이 : 1\n",
      "헤드라인의 최대 길이 : 17\n",
      "헤드라인의 평균 길이 : 9.48406672155643\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('헤드라인의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('헤드라인의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('헤드라인의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('headlines')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 63\n",
    "headlines_max_len = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 63 이하인 샘플의 비율: 0.9826284064688602\n",
      "전체 샘플 중 길이가 11 이하인 샘플의 비율: 0.9154799296597851\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88815\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant an alumnus of upgrad and iiit b pg...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india by wickets in the f...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>with aegon life iterm insurance plan customers...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "      <td>pakistani singer rahat fateh ali khan has deni...</td>\n",
       "      <td>sostoken rahat fateh ali khan denies getting n...</td>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>govt directs alok verma to join work day befor...</td>\n",
       "      <td>weeks after ex cbi director alok verma told th...</td>\n",
       "      <td>sostoken govt directs alok verma to join work ...</td>\n",
       "      <td>govt directs alok verma to join work day befor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "5  rahat fateh ali khan denies getting notice for...   \n",
       "7  govt directs alok verma to join work day befor...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant an alumnus of upgrad and iiit b pg...   \n",
       "2  new zealand defeated india by wickets in the f...   \n",
       "3  with aegon life iterm insurance plan customers...   \n",
       "5  pakistani singer rahat fateh ali khan has deni...   \n",
       "7  weeks after ex cbi director alok verma told th...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "5  sostoken rahat fateh ali khan denies getting n...   \n",
       "7  sostoken govt directs alok verma to join work ...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "5  rahat fateh ali khan denies getting notice for...  \n",
       "7  govt directs alok verma to join work day befor...  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data를 numpy array로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 섞기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81415 86411  1654 ... 24710 47457 20983]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 17763\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 71052\n",
      "훈련 레이블의 개수 : 71052\n",
      "테스트 데이터의 개수 : 17763\n",
      "테스트 레이블의 개수 : 17763\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vocabulary 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 66249\n",
      "등장 빈도가 9번 이하인 희귀 단어의 수: 48645\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 17604\n",
      "단어 집합에서 희귀 단어의 비율: 73.42752343431599\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.9349925442281943\n"
     ]
    }
   ],
   "source": [
    "threshold = 10\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 17000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 17,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6946, 24, 6669, 5, 8159, 6, 9985, 1111, 8587, 1761, 4, 1882, 2171, 6, 1485, 715, 12, 3, 11965, 1792, 2432, 23, 1365, 16, 997, 69, 5, 252, 1422, 1, 1761, 6, 8159, 2554, 808, 450, 1087, 61, 5105, 2, 3, 203, 3389, 23, 2329, 1907, 16, 1634, 2201, 8159, 278, 417, 2171, 8, 2202, 121, 8762], [72, 913, 1010, 31, 14, 895, 4, 1, 763, 428, 23, 4682, 7, 133, 2, 356, 43, 50, 176, 5, 1, 158, 176, 428, 253, 31, 373, 24, 194, 176, 135, 1080, 358, 5974, 19, 1506, 7329, 1595, 285, 2, 494, 1, 176, 1814, 31, 646, 70, 75, 9, 43, 2721, 2816, 390, 4, 428, 199, 595], [16, 16723, 232, 1668, 791, 805, 87, 4610, 429, 2433, 7, 453, 15317, 612, 6, 1669, 71, 2, 7, 2760, 1, 791, 1851, 232, 1129, 71, 2, 1, 549, 5, 69, 41, 805, 26, 3476, 2, 48, 2129, 10702, 8031, 6, 4145, 266, 2345, 7330, 16, 3, 232, 1129, 71, 2, 1, 549, 5, 69]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 28958\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 19905\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9053\n",
      "단어 집합에서 희귀 단어의 비율: 68.73748187029491\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.701357714461381\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 5060, 8340, 3, 847, 4, 1949, 9, 1081, 1070], [1, 41, 1268, 383, 580, 592, 490, 8, 186, 642, 3100], [1, 7744, 208, 7745, 1646, 515, 941, 1669, 902, 371], [1, 935, 190, 312, 729, 448, 5, 2009, 1805], [1, 23, 2644, 2958, 2959, 3, 717, 297, 53, 159, 47, 2184]]\n",
      "target\n",
      "decoder  [[5060, 8340, 3, 847, 4, 1949, 9, 1081, 1070, 2], [41, 1268, 383, 580, 592, 490, 8, 186, 642, 3100, 2], [7744, 208, 7745, 1646, 515, 941, 1669, 902, 371, 2], [935, 190, 312, 729, 448, 5, 2009, 1805, 2], [23, 2644, 2958, 2959, 3, 717, 297, 53, 159, 47, 2184, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 9000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 71052\n",
      "훈련 레이블의 개수 : 71052\n",
      "테스트 데이터의 개수 : 17763\n",
      "테스트 레이블의 개수 : 17763\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 108\n",
    "hidden_size = 192\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 63)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 63, 108)      1836000     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, 63, 192), (N 231168      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, 63, 192), (N 295680      lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 108)    972000      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, 63, 192), (N 295680      lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, None, 192),  231168      embedding_5[0][0]                \n",
      "                                                                 lstm_10[0][1]                    \n",
      "                                                                 lstm_10[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 9000)   1737000     lstm_11[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,598,696\n",
      "Trainable params: 5,598,696\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어텐션 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 63)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 63, 108)      1836000     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, 63, 192), (N 231168      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, 63, 192), (N 295680      lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 108)    972000      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, 63, 192), (N 295680      lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, None, 192),  231168      embedding_5[0][0]                \n",
      "                                                                 lstm_10[0][1]                    \n",
      "                                                                 lstm_10[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 192),  73920       lstm_10[0][0]                    \n",
      "                                                                 lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 384)    0           lstm_11[0][0]                    \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 9000)   3465000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,400,616\n",
      "Trainable params: 7,400,616\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "278/278 [==============================] - 120s 431ms/step - loss: 6.1788 - val_loss: 5.6194\n",
      "Epoch 2/50\n",
      "278/278 [==============================] - 119s 428ms/step - loss: 5.6714 - val_loss: 5.3434\n",
      "Epoch 3/50\n",
      "278/278 [==============================] - 119s 427ms/step - loss: 5.2919 - val_loss: 5.0177\n",
      "Epoch 4/50\n",
      "278/278 [==============================] - 119s 428ms/step - loss: 4.8686 - val_loss: 4.7092\n",
      "Epoch 5/50\n",
      "278/278 [==============================] - 118s 426ms/step - loss: 4.5407 - val_loss: 4.5127\n",
      "Epoch 6/50\n",
      "278/278 [==============================] - 117s 422ms/step - loss: 4.2892 - val_loss: 4.3687\n",
      "Epoch 7/50\n",
      "278/278 [==============================] - 117s 422ms/step - loss: 4.0872 - val_loss: 4.2670\n",
      "Epoch 8/50\n",
      "278/278 [==============================] - 118s 423ms/step - loss: 3.9166 - val_loss: 4.1852\n",
      "Epoch 9/50\n",
      "278/278 [==============================] - 118s 425ms/step - loss: 3.7680 - val_loss: 4.1208\n",
      "Epoch 10/50\n",
      "278/278 [==============================] - 120s 432ms/step - loss: 3.6353 - val_loss: 4.0640\n",
      "Epoch 11/50\n",
      "278/278 [==============================] - 121s 434ms/step - loss: 3.5179 - val_loss: 4.0225\n",
      "Epoch 12/50\n",
      "278/278 [==============================] - 122s 439ms/step - loss: 3.4122 - val_loss: 3.9907\n",
      "Epoch 13/50\n",
      "278/278 [==============================] - 120s 433ms/step - loss: 3.3151 - val_loss: 3.9650\n",
      "Epoch 14/50\n",
      "278/278 [==============================] - 120s 430ms/step - loss: 3.2262 - val_loss: 3.9353\n",
      "Epoch 15/50\n",
      "278/278 [==============================] - 123s 441ms/step - loss: 3.1423 - val_loss: 3.9199\n",
      "Epoch 16/50\n",
      "278/278 [==============================] - 120s 430ms/step - loss: 3.0654 - val_loss: 3.9038\n",
      "Epoch 17/50\n",
      "278/278 [==============================] - 119s 428ms/step - loss: 2.9947 - val_loss: 3.8858\n",
      "Epoch 18/50\n",
      "278/278 [==============================] - 118s 423ms/step - loss: 2.9282 - val_loss: 3.8845\n",
      "Epoch 19/50\n",
      "278/278 [==============================] - 118s 425ms/step - loss: 2.8668 - val_loss: 3.8774\n",
      "Epoch 20/50\n",
      "278/278 [==============================] - 119s 428ms/step - loss: 2.8057 - val_loss: 3.8714\n",
      "Epoch 21/50\n",
      "278/278 [==============================] - 118s 424ms/step - loss: 2.7505 - val_loss: 3.8685\n",
      "Epoch 22/50\n",
      "278/278 [==============================] - 118s 425ms/step - loss: 2.6975 - val_loss: 3.8690\n",
      "Epoch 23/50\n",
      "278/278 [==============================] - 119s 426ms/step - loss: 2.6477 - val_loss: 3.8682\n",
      "Epoch 24/50\n",
      "278/278 [==============================] - 119s 427ms/step - loss: 2.5995 - val_loss: 3.8723\n",
      "Epoch 25/50\n",
      "278/278 [==============================] - 120s 431ms/step - loss: 2.5551 - val_loss: 3.8709\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : billionaire mark zuckerberg led social media major facebook has debuted at rank on fortune list of the world largest companies in facebook has registered straight profitable quarters and reported a revenue of billion in its last fiscal chinese internet giant tencent and entrepreneur jack ma alibaba have also debuted on the list this year \n",
      "실제 요약 : facebook enters fortune global list for the first time \n",
      "예측 요약 :  facebook posts highest ever list of facebook\n",
      "\n",
      "\n",
      "원문 : social media giant facebook r d division building is reportedly working on modular smartphones with parts the company has filed for a patent that details a modular electromagnetic device that will let users switch out outdated components building is led by a former google executive who the development of its now scrapped modular smartphone project \n",
      "실제 요약 : facebook working on smartphones reports \n",
      "예측 요약 :  facebook messenger to shut down by\n",
      "\n",
      "\n",
      "원문 : the founder and majority owner of who in s persuaded americans to eat at fast food restaurants then considered a trash fish is now worth billion started fishing in when he was a college with in his pocket now sells to chains including and \n",
      "실제 요약 : us man who once sold trash fish is now a billionaire \n",
      "예측 요약 :  firm recalls lakh for rice oil products\n",
      "\n",
      "\n",
      "원문 : economic and political weekly editor has resigned from his position after a legal notice was served by adani group to the academic journal the notice was in regard to a story which allegedly sought to expose an adani group company for earning a tax refund of crore the notice claimed the story was misleading and derogatory \n",
      "실제 요약 : editor steps down after legal notice from adani group \n",
      "예측 요약 :  india chief quits over defamation case against bcci\n",
      "\n",
      "\n",
      "원문 : akshay kumar who is currently his daughter while shooting gold has said his respect for wife twinkle khanna has increased i have to confess that a little girl is a tough job he added akshay further said i do not know how she designs looks after our children and still manages to stay calm on most days \n",
      "실제 요약 : respect for twinkle increased akshay on \n",
      "예측 요약 :  akshay wife was paid for me akshay kumar\n",
      "\n",
      "\n",
      "원문 : a man slammed iifa awards on facebook for falsely claiming that the ceremony will feature shah rukh khan priyanka chopra and hollywood actors julia roberts and matt he also shared posters of the event featuring these actors he further claimed that people paid to for their kids to dance with salman khan but the activity did not happen n \n",
      "실제 요약 : man slams iifa for false claim of srk priyanka appearance \n",
      "예측 요약 :  canadian fan trolled for srk deepika wedding\n",
      "\n",
      "\n",
      "원문 : lipstick under my burkha director shrivastava has said the have a problem with female point of view while adding they re not comfortable with something that questions the status quo she also said that the male perspective which popular culture has led to discrimination against women and makes stalking seem like love makes harassment abuse of women okay \n",
      "실제 요약 : censors have issue with female director \n",
      "예측 요약 :  i am not a man who is a industry director\n",
      "\n",
      "\n",
      "원문 : finance minister arun jaitley on friday said that the financial year may soon begin from january in sync with the calendar year the matter of changing financial year is under consideration of the government he told the lok sabha in may madhya pradesh became india first state to shift its financial year format to january december from the present april march cycle \n",
      "실제 요약 : financial year may soon begin from january jaitley \n",
      "예측 요약 :  india to be celebrated as next year long\n",
      "\n",
      "\n",
      "원문 : a man threw his three year old daughter in a canal in haryana faridabad to become a tantrik the police claimed while the man claimed that his daughter went missing on july and filed a kidnapping complaint the truth was later revealed when police scanned cctv footage of the area the man confessed to his crime after the police confronted him \n",
      "실제 요약 : man throws year old daughter in canal to become tantrik \n",
      "예측 요약 :  man chops off baby penis in haryana\n",
      "\n",
      "\n",
      "원문 : pro kannada group karnataka vedike protested in front of the bruhat bengaluru mahanagara palike demanding the removal of all the hindi signboards in the city further stating that over sign boards in the state should be in kannada the group threatened to the hindi boards if their demands were not met \n",
      "실제 요약 : pro kannada group demands removal of hindi \n",
      "예측 요약 :  mns workers protest against potholes on lucknow\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summa 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.getenv('HOME')+'/mini_projects/_E-11_summarize/data/news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Text parameter must be a Unicode object (str)!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-0f575c7d5e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/summa/summarizer.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, ratio, words, language, split, scores, additional_stopwords)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_stopwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Text parameter must be a Unicode object (str)!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# Gets a list of processed sentences.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Text parameter must be a Unicode object (str)!"
     ]
    }
   ],
   "source": [
    "summarize(news1.txt, words = 9, split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(os.getenv(\"HOME\")+\"/mini_projects/_E-11_summarize/data/news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = []\n",
    "\n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_headlines = []\n",
    "\n",
    "for s in data['headlines']:\n",
    "    clean_headlines.append(preprocess_sentence(s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('헤드라인의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('헤드라인의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('헤드라인의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('headlines')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 63\n",
    "headlines_max_len = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 10\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 17000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 17,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_vocab = 9000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "헤드라인에 대해서도 불용어 제거 시행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 섞기 코드가 이해 안가네"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델로 아담 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫번째 시도   \n",
    "   \n",
    "   \n",
    "text와 headlines 모두 불용어 제거   \n",
    "   \n",
    "text_max_len = 40   \n",
    "   \n",
    "headlines_max_len = 8   \n",
    "   \n",
    "src_vocab = 20000   \n",
    "tar_vocab = 10000   \n",
    "   \n",
    "   \n",
    "훈련 데이터의 개수 : 71614\n",
    "훈련 레이블의 개수 : 71614\n",
    "테스트 데이터의 개수 : 17903\n",
    "테스트 레이블의 개수 : 17903\n",
    "\n",
    "embedding_dim = 128   \n",
    "hidden_size = 256   \n",
    "   \n",
    "optimizer='adam'\n",
    "   \n",
    "   \n",
    "Epoch 14/50   \n",
    "280/280 [==============================] - 92s 328ms/step - loss: 2.9265 - val_loss: 4.2610   \n",
    "\n",
    "원문 : professor yash pal renowned scientist passed away monday night noida hospital pal awarded padma bhushan padma vibhushan known contribution study cosmic rays tata institute fundamental research also featured famous science series turning point doordarshan \n",
    "실제 요약 : veteran scientist professor yash pal passes away \n",
    "예측 요약 :  indrani mukerjea died due ganga\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두번째 시도      \n",
    "text와 headlines 모두 불용어 제거 안 함   \n",
    "   \n",
    "text_max_len = 63   \n",
    "\n",
    "headlines_max_len = 11   \n",
    "\n",
    "\n",
    "src_vocab = 17,000   \n",
    "tar_vocab = 9000   \n",
    "   \n",
    "   \n",
    "훈련 데이터의 개수 : 71052   \n",
    "훈련 레이블의 개수 : 71052   \n",
    "테스트 데이터의 개수 : 17763   \n",
    "테스트 레이블의 개수 : 17763   \n",
    "   \n",
    "   \n",
    "embedding_dim = 108   \n",
    "hidden_size = 192   \n",
    "\n",
    "원문 : economic and political weekly editor has resigned from his position after a legal notice was served by adani group to the academic journal the notice was in regard to a story which allegedly sought to expose an adani group company for earning a tax refund of crore the notice claimed the story was misleading and derogatory \n",
    "실제 요약 : editor steps down after legal notice from adani group \n",
    "예측 요약 :  india chief quits over defamation case against bcci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
