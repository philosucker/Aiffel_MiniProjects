{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/mini_projects/rps/train/scissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/mini_projects/rps/train/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/mini_projects/rps/train/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/mini_projects/rps/train/scissor\"\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "target_size=(28,28) \n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/mini_projects/rps/train/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/mini_projects/rps/train/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련 데이터 적재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 루브릭 평가문항 2. 오버피팅을 극복하기 위한 적절한 시도가 있었는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. 훈련 데이터셋에 소요된 총 이미지 개수 5702 장  / 테스트 데이터 셋에 소요된 총 이미지 개수 643장\n",
    "1. 훈련 데이터셋과 테스트 데이터셋의 구분\n",
    "2. 테스트 데이터셋의 이미지들은 훈련 데이터셋 있는 이미지들과 최대한 다른 이미지들로 선별하여 분류\n",
    "3. 데이터 normalization 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 5698 입니다.\n",
      "x_train shape: (5702, 28, 28, 3)\n",
      "y_train shape: (5702,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data= 5702  \n",
    "    img_size=28\n",
    "    color=3 \n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/mini_projects/rps/train/\"   \n",
    "\n",
    "(x_train, y_train)=load_data(image_dir_path)    # 핵심 함수 : 훈련데이터의 입력과 레이블 생성하는 함수!!\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 데이터 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0  최대값: 255\n"
     ]
    }
   ],
   "source": [
    "print('최소값:',np.min(x_train), ' 최대값:',np.max(x_train))\n",
    "\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "# Conv2D(16) 얼마나 다양한 이미지의 특징을 살펴볼 것인가? (입력 이미지가 다양할 수록 더 많은 특징 고려 필요)\n",
    "# input_shape=(28,28,3) >> 입력 이미지의 형태 3 : 채널 정보 컬러사진 RGB니까 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "# Conv2D(32) 얼마나 다양한 이미지의 특징을 살펴볼 것인가? (입력 이미지가 다양할 수록 더 많은 특징 고려 필요)\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "# Dense(32) : 분류기 알고리즘을 얼마나 복잡하게 할 것인가? (복잡한 문제일 수록 이 숫자를 늘린다) \n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "# 최종 분류기의 클래스 숫자 3 : 가위, 바위, 보\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 훈련 (훈련 데이터 셋 학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "179/179 [==============================] - 4s 20ms/step - loss: 0.9591 - accuracy: 0.5284\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.7524\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8430\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8923\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9225\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9476\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9593\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9730\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9819\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f63e8582250>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 루브릭 평가문항 1. 이미지 분류기 모델이 성공적으로 만들어졌는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >훈련결과 : 정확도 98%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 데이터 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 642 입니다.\n",
      "x_test shape: (643, 28, 28, 3)\n",
      "y_test shape: (643,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=643   \n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/mini_projects/rps/test/\"\n",
    "\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0  최대값: 255\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('최소값:',np.min(x_test), ' 최대값:',np.max(x_test))\n",
    "\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터로 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 2s - loss: 0.1270 - accuracy: 0.9533\n",
      "test_loss: 0.1270076036453247 \n",
      "test_accuracy: 0.9533436894416809\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >테스트 정확도: 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 11, 11, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 448,003\n",
      "Trainable params: 448,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "179/179 [==============================] - 4s 23ms/step - loss: 0.9338 - accuracy: 0.5335\n",
      "Epoch 2/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7832\n",
      "Epoch 3/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8881\n",
      "Epoch 4/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9321\n",
      "Epoch 5/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9639\n",
      "Epoch 6/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9747\n",
      "Epoch 7/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9828\n",
      "Epoch 8/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9893\n",
      "Epoch 9/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9960\n",
      "Epoch 10/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9979\n",
      "Epoch 11/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9996\n",
      "Epoch 12/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9998\n",
      "Epoch 13/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.9998\n",
      "Epoch 14/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.9998\n",
      "Epoch 15/15\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f63e83c6c50>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=128\n",
    "n_dense=128\n",
    "n_train_epoch=15\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 모델 재훈련\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 루브릭 평가문항 3. 분류모델의 test accuracy가 기준 (60%) 이상 높게 나왔는가? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >>최종결과 : 정확도 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 2s - loss: 0.0408 - accuracy: 0.9907\n",
      "test_loss: 0.04082171246409416 \n",
      "test_accuracy: 0.9906687140464783\n"
     ]
    }
   ],
   "source": [
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트 일지\n",
    "2020년 1월 5일과 6일 이틀에 걸쳐 작업을 했다.   \n",
    "   \n",
    "   \n",
    "__1. 1차 시기 (실은 약 200여회차...)__   \n",
    "   \n",
    "훈련 데이터셋 3000장, 테스트 데이터셋 300장 으로 모델을 평가했다.   \n",
    "학습시 정확도는 90%가 넘었지만 테스트 정확도는 40%대에 머물렀다.   \n",
    "Conv2D 인자와 Dense 인자, 총 3개의 하이퍼 파라미터를   \n",
    "두자리 수부터 네자리 수까지 가능한 모든 조합으로 섞어   \n",
    "200여회 남짓 모델을 돌려보았지만   \n",
    "테스트 정확도가 60%를 넘지 못했다.   \n",
    "   \n",
    "__2. 1차 시기의 실패 원인__   \n",
    "   \n",
    "너무 빡친 나머지 팀 슬랙에 여쭤보니   \n",
    "훈련 데이터셋과 테스트 데이터셋에 쓴 이미지들을 선별하지 않고 그냥 사용한 점이   \n",
    "문제인 것 같다는 지적을 받았다.   \n",
    "같은 팀원 분의 조언대로 가위, 바위, 보 이미지들을 육안으로 보아도 분명히 식별가능한 데이터로 분류하여   \n",
    "각각 훈련 데이터셋과, 테스트데이터셋에 나누어 분류하니   \n",
    "테스트 이미지는 218장, 훈련 이미지는 2301장만 남아   \n",
    "약 30%의 데이터 손실이 일어났다.   \n",
    "하지만 이렇게 했을 때도 최종 테스트 정확도가 50%를 넘지 못했다.   \n",
    "   \n",
    "__3. 2차 시기__   \n",
    "   \n",
    "훈련 데이터 셋의 크기는 그대로 두고   \n",
    "테스트 데이터 셋의 크기를 2배 늘려 425장을 사용했다.   \n",
    "그 결과 테스트 정확도가 70%까지 나왔다.  \n",
    "   \n",
    "__4. 3차 시기__   \n",
    "   \n",
    "훈련 데이터셋의 크기를 2배로 늘려 4050장을 사용하고   \n",
    "테스트 데이터셋은 원래대로 218장을 사용했더니   \n",
    "최종 테스트 정확도가 100%까지 나왔다.   \n",
    "하지만 3차 시기의 경우 학습시 정확도가 97%였던 것에 비해   \n",
    "최초 모델 평가에서 99%가 나와   \n",
    "오버 피팅이 의심되었다. 하지만 원인은 알 수 없었다. (퍼실님 왜 이렇게 되는 건지 알려 주실 수 있을까요?)   \n",
    "   \n",
    "__5. 4차 시기__   \n",
    "   \n",
    "훈련 데이터셋을 5702장, 테스트 데이터셋을 643장 사용하여 돌려본 결과  \n",
    "학습시 정확도는 98%   \n",
    "최초 테스트 정확도는 96%   \n",
    "하이퍼 파라미터 조정결과 99%가 나왔다.   \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고   \n",
    "   \n",
    "\n",
    "__데이터의 질이 중요하다는 걸 깨달았을 때__   \n",
    "처음엔 너무나 실망스러웠다.   \n",
    "훈련데이터와 테스트데이터를 나눌 때, 테스트 데이터를 unseen data로 남겨둬야 하는데 그렇게 해선   \n",
    "결코 원하는 결과가 나오지 않는다는 사실이 너무나 끔찍했다.   \n",
    "하지만 마음을 가라 앉히고 내가 이 모델에서 무엇을 기대해야 하는 지를 생각해보았다.\n",
    "1. 이미지의 퀄리티가 너무 낮기 때문에\n",
    "2. 다양한 각도에서 촬영한 가위, 바위, 보 이미지 대신 2차원 상에서 분명히 구분가능한 이미지 들로만 데이터를 정리한 뒤   \n",
    "3. 훈련데이터와 테스트데이터를 비슷한 수준의 이미지로 분류하여 모델을 돌림으로써   \n",
    "4. 이 프로젝트에서 기대할 수 있는 것은 문자 그대로 명백한 가위, 바위, 보 이미지를 분류해내는 것이 최선이다.   \n",
    "\n",
    "__나아가 이 프로젝트에서 내가 무엇을 배웠는지를 생각해보았다.__   \n",
    "1. 데이터의 전처리는 단순히 알고리즘에 넣을 수 있게 데이터의 수치를 조정하는 것만이 아니라   \n",
    "   데이터의 질을 평균 이상으로 맞춰주는 작업도 포함된다.   \n",
    "2. 데이터의 질도 중요하지만, 그 전에 내가 만들고자 하는 모델이 어느 정도 수준의 결과를 낼 수 있는 모델인지를 먼저 분명히해야 한다.   \n",
    "3. 모델의 성능과 데이터의 수준을 정확히 파악했다 하더라도, 모델의 성능을 개선시키는 방법을 알지 못하면 1회용 모델을 만들게 될 뿐이다.   \n",
    "4. 데이터의 질 문제를 해결해도, 절대적인 데이터 양이 적으면 좋은 성능을 기대하기 어렵다.   \n",
    "5. 나의 지식 수준이 한참 낮아 모델이 정말 어떤 원리로 작동하는지 모르는 상태에서는 절대로 결과에 욕심을 내서도 짜증을 내서도 안된다.   \n",
    "6. 컴퓨터도 사용자가 너무 무식하면 두손 놓아버린다. (ResourceExhaustedError가 한 번 뜨니 더이상 코드런이 안돼 컴퓨터를 껐다 켜야 했다)   \n",
    "   \n",
    "__반성할 점__\n",
    "1. 오늘 하루 종일 뇌가 가위바위보에만 쏠려버려 민채퍼실님의 코딩마스터 수업을 거의 못들었다..   \n",
    "2. 1차 시기에서 그토록 많은 에너지와 시간을 낭비하지 않을 수 있었다. 가만히 생각해 보면 이미지 퀄리티를 고려해야한다는 점이   \n",
    "   노드에 설명돼 있었다. 머리를 쓰자...   \n",
    "   \n",
    "__더 공부해야할 부분__   \n",
    "함수가 길어지면 변수가 인자가 되고, 그 변수가 다시 다른 함수의 인자가 되고, 꼬리에 꼬리를 물면서 전체 그림을 놓친다.   \n",
    "기본적인 문자열 함수들에 대한 이해가 부족하다. 슬라이싱, 인덱싱 기법들...   \n",
    "넘파이 배열에 너무 약하다.   \n",
    "딥러닝 용어를 더 공부해야겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
